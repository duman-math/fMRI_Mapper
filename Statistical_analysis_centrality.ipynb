{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "77093362",
      "metadata": {
        "id": "77093362"
      },
      "source": [
        "##Analysis of  the relationship between the centrality scores and phenotypic data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1edf33af",
      "metadata": {
        "id": "1edf33af"
      },
      "outputs": [],
      "source": [
        "# Load and examine the datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the datasets\n",
        "centrality_df = pd.read_csv('centrality_scores_NYU.csv')\n",
        "phenotypic_df = pd.read_csv('NYU_phenotypic.csv')\n",
        "\n",
        "print(\"Centrality scores dataset:\")\n",
        "print(centrality_df.head())\n",
        "print(\"\\nCentrality dataset shape:\", centrality_df.shape)\n",
        "print(\"\\nPhenotypic dataset:\")\n",
        "print(phenotypic_df.head())\n",
        "print(\"\\nPhenotypic dataset shape:\", phenotypic_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84215ce2",
      "metadata": {
        "id": "84215ce2"
      },
      "outputs": [],
      "source": [
        "# Clean and prepare the data\n",
        "# Replace -999 values with NaN in phenotypic data\n",
        "phenotypic_df = phenotypic_df.replace(-999, np.nan)\n",
        "\n",
        "# Check the centrality data structure - it seems to have a different format\n",
        "print(\"Centrality columns:\", centrality_df.columns.tolist())\n",
        "print(\"\\nFirst few rows of centrality data:\")\n",
        "print(centrality_df.head())\n",
        "\n",
        "# Check if subject_number column exists and examine its values\n",
        "if 'subject_number' in centrality_df.columns:\n",
        "    print(\"\\nSubject numbers in centrality data:\")\n",
        "    print(centrality_df['subject_number'].head(10))\n",
        "\n",
        "print(\"\\nScanDir ID in phenotypic data:\")\n",
        "print(phenotypic_df['ScanDir ID'].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72a36738",
      "metadata": {
        "id": "72a36738"
      },
      "outputs": [],
      "source": [
        "# Check for potential matching between datasets\n",
        "# Convert subject numbers to see if they match ScanDir IDs in any way\n",
        "centrality_subjects = centrality_df['subject_number'].dropna().astype(int)\n",
        "phenotypic_ids = phenotypic_df['ScanDir ID'].dropna().astype(int)\n",
        "\n",
        "print(\"Centrality subject numbers range:\", centrality_subjects.min(), \"to\", centrality_subjects.max())\n",
        "print(\"Phenotypic ScanDir ID range:\", phenotypic_ids.min(), \"to\", phenotypic_ids.max())\n",
        "\n",
        "# Check if any direct matches exist\n",
        "common_ids = set(centrality_subjects) & set(phenotypic_ids)\n",
        "print(\"Direct matches between datasets:\", len(common_ids))\n",
        "\n",
        "# Check if the datasets have the same number of subjects\n",
        "print(\"Number of subjects in centrality data:\", len(centrality_subjects))\n",
        "print(\"Number of subjects in phenotypic data:\", len(phenotypic_ids))\n",
        "\n",
        "# Let's check if the order might be the same by examining both datasets\n",
        "print(\"\\nFirst 10 centrality subjects:\", centrality_subjects.head(10).tolist())\n",
        "print(\"First 10 phenotypic IDs:\", phenotypic_ids.head(10).tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8391eb",
      "metadata": {
        "id": "7f8391eb"
      },
      "outputs": [],
      "source": [
        "# Merge the datasets on matching IDs\n",
        "merged_df = pd.merge(\n",
        "    centrality_df,\n",
        "    phenotypic_df,\n",
        "    left_on='subject_number',\n",
        "    right_on='ScanDir ID',\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "print(\"Merged dataset shape:\", merged_df.shape)\n",
        "print(\"\\nColumns in merged dataset:\")\n",
        "print(merged_df.columns.tolist())\n",
        "\n",
        "# Check the DX distribution\n",
        "print(\"\\nDX distribution:\")\n",
        "dx_counts = merged_df['DX'].value_counts().sort_index()\n",
        "print(dx_counts)\n",
        "\n",
        "# Check for missing values in key columns\n",
        "key_columns = ['DX', 'ADHD Index', 'Inattentive', 'Hyper/Impulsive',\n",
        "               'betweenness_centrality', 'closeness_centrality', 'degree_centrality']\n",
        "print(\"\\nMissing values in key columns:\")\n",
        "for col in key_columns:\n",
        "    if col in merged_df.columns:\n",
        "        missing = merged_df[col].isna().sum()\n",
        "        print(col + \":\", missing)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e323bdab",
      "metadata": {
        "id": "e323bdab"
      },
      "source": [
        "\n",
        "\n",
        "The merged dataset has 216 subjects with complete centrality and phenotypic data.\n",
        "\n",
        "\n",
        "\n",
        "The DX distribution shows:\n",
        "- DX = 0 (TDC - Typically Developing Controls): 98 subjects  \n",
        "- DX = 1 (ADHD-Inattentive): 73 subjects\n",
        "- DX = 2 (ADHD-Hyperactive/Impulsive): 2 subjects  \n",
        "- DX = 3 (ADHD-Combined): 43 subjects\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac485c47",
      "metadata": {
        "id": "ac485c47"
      },
      "outputs": [],
      "source": [
        "# Clean the data and prepare for analysis\n",
        "# Remove rows with missing ADHD measures\n",
        "clean_df = merged_df.dropna(subset=['ADHD Index', 'Inattentive', 'Hyper/Impulsive'])\n",
        "\n",
        "print(\"Clean dataset shape:\", clean_df.shape)\n",
        "\n",
        "# Create ADHD group (DX = 1, 2, 3) vs TDC (DX = 0)\n",
        "clean_df['Group'] = clean_df['DX'].apply(lambda x: 'ADHD' if x in [1, 2, 3] else 'TDC')\n",
        "\n",
        "print(\"\\nGroup distribution:\")\n",
        "group_counts = clean_df['Group'].value_counts()\n",
        "print(group_counts)\n",
        "\n",
        "# Prepare centrality measures for analysis\n",
        "centrality_measures = ['betweenness_centrality', 'closeness_centrality', 'degree_centrality']\n",
        "adhd_measures = ['ADHD Index', 'Inattentive', 'Hyper/Impulsive']\n",
        "\n",
        "print(\"\\nData ready for analysis\")\n",
        "print(\"Centrality measures:\", centrality_measures)\n",
        "print(\"ADHD measures:\", adhd_measures)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c7ba95",
      "metadata": {
        "id": "18c7ba95"
      },
      "source": [
        "###Create the scatter plots showing relationships between centrality scores and ADHD measures:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa78715a",
      "metadata": {
        "id": "fa78715a"
      },
      "outputs": [],
      "source": [
        "# Create scatter plots for centrality scores vs ADHD measures\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
        "fig.suptitle('Centrality Scores vs ADHD Measures', fontsize=16, y=0.98)\n",
        "\n",
        "for i, centrality in enumerate(centrality_measures):\n",
        "    for j, adhd_measure in enumerate(adhd_measures):\n",
        "        ax = axes[i, j]\n",
        "\n",
        "        # Create scatter plot\n",
        "        x = clean_df[adhd_measure]\n",
        "        y = clean_df[centrality]\n",
        "\n",
        "        # Color by group\n",
        "        colors = ['red' if group == 'ADHD' else 'blue' for group in clean_df['Group']]\n",
        "        ax.scatter(x, y, c=colors, alpha=0.6, s=30)\n",
        "\n",
        "        # Calculate correlation and one-tailed p-value\n",
        "        corr, p_value_two_tailed = stats.pearsonr(x, y)\n",
        "        p_value_one_tailed = p_value_two_tailed / 2\n",
        "\n",
        "        # Add correlation and p-value to plot\n",
        "        ax.set_xlabel(adhd_measure)\n",
        "        ax.set_ylabel(centrality.replace('_', ' ').title())\n",
        "        ax.set_title('r = ' + str(round(corr, 3)) + ', p = ' + str(round(p_value_one_tailed, 4)) + ' (one-tailed)')\n",
        "\n",
        "        # Add trend line\n",
        "        z = np.polyfit(x, y, 1)\n",
        "        p = np.poly1d(z)\n",
        "        ax.plot(x, p(x), \"k--\", alpha=0.8, linewidth=1)\n",
        "\n",
        "# Add legend\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [Patch(facecolor='red', label='ADHD'),\n",
        "                   Patch(facecolor='blue', label='TDC')]\n",
        "fig.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(0.98, 0.95))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db1303b",
      "metadata": {
        "id": "4db1303b"
      },
      "outputs": [],
      "source": [
        "# Create box plots comparing ADHD groups vs TDC for each centrality measure\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle('Centrality Scores: ADHD vs TDC Groups', fontsize=16)\n",
        "\n",
        "for i, centrality in enumerate(centrality_measures):\n",
        "    ax = axes[i]\n",
        "\n",
        "    # Create box plot\n",
        "    adhd_data = clean_df[clean_df['Group'] == 'ADHD'][centrality]\n",
        "    tdc_data = clean_df[clean_df['Group'] == 'TDC'][centrality]\n",
        "\n",
        "    box_data = [tdc_data, adhd_data]\n",
        "    bp = ax.boxplot(box_data, labels=['TDC', 'ADHD'], patch_artist=True)\n",
        "\n",
        "    # Color the boxes\n",
        "    bp['boxes'][0].set_facecolor('blue')\n",
        "    bp['boxes'][0].set_alpha(0.6)\n",
        "    bp['boxes'][1].set_facecolor('red')\n",
        "    bp['boxes'][1].set_alpha(0.6)\n",
        "\n",
        "    # Perform one-tailed t-test (assuming ADHD might have different centrality)\n",
        "    t_stat, p_value_two_tailed = stats.ttest_ind(adhd_data, tdc_data)\n",
        "    p_value_one_tailed = p_value_two_tailed / 2\n",
        "\n",
        "    # Add statistics to plot\n",
        "    ax.set_ylabel(centrality.replace('_', ' ').title())\n",
        "    ax.set_title('p = ' + str(round(p_value_one_tailed, 4)) + ' (one-tailed)')\n",
        "\n",
        "    # Add mean values as text\n",
        "    adhd_mean = adhd_data.mean()\n",
        "    tdc_mean = tdc_data.mean()\n",
        "    ax.text(0.02, 0.98, 'TDC mean: ' + str(round(tdc_mean, 4)),\n",
        "            transform=ax.transAxes, verticalalignment='top', fontsize=9)\n",
        "    ax.text(0.02, 0.90, 'ADHD mean: ' + str(round(adhd_mean, 4)),\n",
        "            transform=ax.transAxes, verticalalignment='top', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "903bf31c",
      "metadata": {
        "id": "903bf31c"
      },
      "outputs": [],
      "source": [
        "# Create box plots for each DX category (0, 1, 2, 3) vs centrality measures\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle('Centrality Scores by Detailed DX Categories', fontsize=16)\n",
        "\n",
        "# Map DX values to labels\n",
        "dx_labels = {0: 'TDC', 1: 'ADHD-I', 2: 'ADHD-H', 3: 'ADHD-C'}\n",
        "\n",
        "for i, centrality in enumerate(centrality_measures):\n",
        "    ax = axes[i]\n",
        "\n",
        "    # Prepare data for each DX category\n",
        "    dx_categories = sorted(clean_df['DX'].unique())\n",
        "    box_data = []\n",
        "    labels = []\n",
        "\n",
        "    for dx in dx_categories:\n",
        "        data = clean_df[clean_df['DX'] == dx][centrality]\n",
        "        if len(data) > 0:  # Only include if there's data\n",
        "            box_data.append(data)\n",
        "            labels.append(dx_labels.get(dx, 'DX=' + str(int(dx))))\n",
        "\n",
        "    # Create box plot\n",
        "    bp = ax.boxplot(box_data, labels=labels, patch_artist=True)\n",
        "\n",
        "    # Color the boxes\n",
        "    colors = ['blue', 'red', 'orange', 'green']\n",
        "    for patch, color in zip(bp['boxes'], colors[:len(bp['boxes'])]):\n",
        "        patch.set_facecolor(color)\n",
        "        patch.set_alpha(0.6)\n",
        "\n",
        "    # Perform ANOVA to test differences between groups\n",
        "    groups = [clean_df[clean_df['DX'] == dx][centrality] for dx in dx_categories]\n",
        "    f_stat, p_value = stats.f_oneway(*groups)\n",
        "\n",
        "    ax.set_ylabel(centrality.replace('_', ' ').title())\n",
        "    ax.set_title('ANOVA p = ' + str(round(p_value, 4)))\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "388660b3",
      "metadata": {
        "id": "388660b3"
      },
      "outputs": [],
      "source": [
        "# Generate comprehensive statistical summary\n",
        "print(\"=== COMPREHENSIVE STATISTICAL ANALYSIS ===\")\n",
        "print()\n",
        "\n",
        "# 1. Correlation analysis between centrality measures and ADHD symptoms\n",
        "print(\"1. CORRELATIONS BETWEEN CENTRALITY MEASURES AND ADHD SYMPTOMS\")\n",
        "print(\"-\" * 60)\n",
        "for centrality in centrality_measures:\n",
        "    print(centrality.replace('_', ' ').title() + \":\")\n",
        "    for adhd_measure in adhd_measures:\n",
        "        corr, p_two = stats.pearsonr(clean_df[centrality], clean_df[adhd_measure])\n",
        "        p_one = p_two / 2\n",
        "        print(\"  vs \" + adhd_measure + \": r = \" + str(round(corr, 4)) +\n",
        "              \", p = \" + str(round(p_one, 4)) + \" (one-tailed)\")\n",
        "    print()\n",
        "\n",
        "# 2. Group comparisons (ADHD vs TDC)\n",
        "print(\"2. GROUP COMPARISONS: ADHD vs TDC\")\n",
        "print(\"-\" * 40)\n",
        "for centrality in centrality_measures:\n",
        "    adhd_data = clean_df[clean_df['Group'] == 'ADHD'][centrality]\n",
        "    tdc_data = clean_df[clean_df['Group'] == 'TDC'][centrality]\n",
        "\n",
        "    t_stat, p_two = stats.ttest_ind(adhd_data, tdc_data)\n",
        "    p_one = p_two / 2\n",
        "\n",
        "    adhd_mean = adhd_data.mean()\n",
        "    tdc_mean = tdc_data.mean()\n",
        "    effect_size = (adhd_mean - tdc_mean) / np.sqrt(((len(adhd_data)-1)*adhd_data.var() +\n",
        "                                                   (len(tdc_data)-1)*tdc_data.var()) /\n",
        "                                                  (len(adhd_data) + len(tdc_data) - 2))\n",
        "\n",
        "    print(centrality.replace('_', ' ').title() + \":\")\n",
        "    print(\"  ADHD mean: \" + str(round(adhd_mean, 6)) + \" (n=\" + str(len(adhd_data)) + \")\")\n",
        "    print(\"  TDC mean:  \" + str(round(tdc_mean, 6)) + \" (n=\" + str(len(tdc_data)) + \")\")\n",
        "    print(\"  t = \" + str(round(t_stat, 3)) + \", p = \" + str(round(p_one, 4)) +\n",
        "          \" (one-tailed), Cohen's d = \" + str(round(effect_size, 3)))\n",
        "    print()\n",
        "\n",
        "# 3. Detailed DX category analysis\n",
        "print(\"3. DETAILED DX CATEGORY ANALYSIS\")\n",
        "print(\"-\" * 35)\n",
        "dx_labels = {0: 'TDC', 1: 'ADHD-Inattentive', 2: 'ADHD-Hyperactive', 3: 'ADHD-Combined'}\n",
        "\n",
        "for centrality in centrality_measures:\n",
        "    print(centrality.replace('_', ' ').title() + \":\")\n",
        "\n",
        "    # Get data for each DX category\n",
        "    dx_categories = sorted(clean_df['DX'].unique())\n",
        "    groups = []\n",
        "    for dx in dx_categories:\n",
        "        data = clean_df[clean_df['DX'] == dx][centrality]\n",
        "        groups.append(data)\n",
        "        mean_val = data.mean()\n",
        "        print(\"  \" + dx_labels.get(dx, 'DX=' + str(int(dx))) + \": mean = \" +\n",
        "              str(round(mean_val, 6)) + \" (n=\" + str(len(data)) + \")\")\n",
        "\n",
        "    # ANOVA\n",
        "    f_stat, p_value = stats.f_oneway(*groups)\n",
        "    print(\"  ANOVA: F = \" + str(round(f_stat, 3)) + \", p = \" + str(round(p_value, 4)))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a143c1a9",
      "metadata": {
        "id": "a143c1a9"
      },
      "source": [
        "#Results\n",
        "\n",
        "## Dataset Overview\n",
        "\n",
        "\n",
        "The datasets were successfully merged on subject IDs, resulting in 212 complete cases with both centrality measures and ADHD phenotypic data.\n",
        "\n",
        "## Key Findings\n",
        "\n",
        "### 1. Correlations Between Brain Centrality and ADHD Symptoms\n",
        "\n",
        "**Betweenness centrality** shows the strongest relationships with ADHD symptoms, particularly with hyperactive/impulsive behaviors (r = 0.177, p = 0.005).\n",
        "\n",
        "### 2. Group Differences: ADHD vs Typically Developing Controls\n",
        "\n",
        "Both **betweenness** and **closeness centrality** are significantly higher in ADHD participants compared to controls, with moderate effect sizes (Cohen's d = 0.37 and 0.31 respectively).\n",
        "\n",
        "### 3. Detailed ADHD Subtype Analysis\n",
        "\n",
        "\n",
        "The analysis reveals significant differences in betweenness centrality across diagnostic groups (ANOVA p = 0.033), with the hyperactive subtype showing the highest values.\n",
        "\n",
        "## Visual Analysis\n",
        "\n",
        "The scatter plots show positive correlations between centrality measures and ADHD symptom severity, while the box plots demonstrate clear group differences between ADHD and control participants.\n",
        "\n",
        "This analysis suggests that individuals with ADHD have altered brain network topology, particularly increased betweenness and closeness centrality, which may reflect compensatory mechanisms or inefficient information processing in neural networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d9235bd",
      "metadata": {
        "id": "3d9235bd"
      },
      "outputs": [],
      "source": [
        "# Start fresh and load the NeuroIMAGE data carefully\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "# Load NeuroIMAGE datasets\n",
        "centrality_ni_df = pd.read_csv('centrality_scores_NI.csv')\n",
        "phenotypic_ni_df = pd.read_csv('NeuroIMAGE_phenotypic.csv')\n",
        "\n",
        "print(\"Loaded NeuroIMAGE datasets successfully\")\n",
        "print(\"Centrality shape:\", centrality_ni_df.shape)\n",
        "print(\"Phenotypic shape:\", phenotypic_ni_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "935d1e62",
      "metadata": {
        "id": "935d1e62"
      },
      "source": [
        "###Analysis between centrality_scores_NI.csv vs NeuroIMAGE_phenotypic.csv. The regression plot between centrality scores and ADHD index, implusivity, inattentiveness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d269a9e",
      "metadata": {
        "id": "1d269a9e"
      },
      "outputs": [],
      "source": [
        "# Load NeuroIMAGE datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "# Load NeuroIMAGE datasets\n",
        "centrality_ni_df = pd.read_csv('centrality_scores_NI.csv')\n",
        "phenotypic_ni_df = pd.read_csv('NeuroIMAGE_phenotypic.csv')\n",
        "\n",
        "print(\"Loaded NeuroIMAGE datasets successfully\")\n",
        "print(\"Centrality shape:\", centrality_ni_df.shape)\n",
        "print(\"Phenotypic shape:\", phenotypic_ni_df.shape)\n",
        "\n",
        "# Examine the structure of both datasets\n",
        "print(\"\\nCentrality columns:\", centrality_ni_df.columns.tolist())\n",
        "print(\"\\nPhenotypic columns:\", phenotypic_ni_df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22a967b",
      "metadata": {
        "id": "f22a967b"
      },
      "outputs": [],
      "source": [
        "# Examine the first few rows of each dataset\n",
        "print(\"First few rows of centrality data:\")\n",
        "print(centrality_ni_df.head())\n",
        "\n",
        "print(\"\\nFirst few rows of phenotypic data:\")\n",
        "print(phenotypic_ni_df.head())\n",
        "\n",
        "# Check subject identifiers\n",
        "print(\"\\nSubject numbers in centrality data:\")\n",
        "print(centrality_ni_df['subject_number'].head(10))\n",
        "\n",
        "print(\"\\nScanDir ID in phenotypic data:\")\n",
        "print(phenotypic_ni_df['ScanDir ID'].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f54fd868",
      "metadata": {
        "id": "f54fd868"
      },
      "outputs": [],
      "source": [
        "# Check for potential matching patterns between subject identifiers\n",
        "print(\"Centrality subject_number range:\")\n",
        "print(\"Min:\", centrality_ni_df['subject_number'].min())\n",
        "print(\"Max:\", centrality_ni_df['subject_number'].max())\n",
        "print(\"Unique count:\", centrality_ni_df['subject_number'].nunique())\n",
        "\n",
        "print(\"\\nPhenotypic ScanDir ID range:\")\n",
        "print(\"Min:\", phenotypic_ni_df['ScanDir ID'].min())\n",
        "print(\"Max:\", phenotypic_ni_df['ScanDir ID'].max())\n",
        "print(\"Unique count:\", phenotypic_ni_df['ScanDir ID'].nunique())\n",
        "\n",
        "# Check if there are any direct matches\n",
        "common_ids = set(centrality_ni_df['subject_number']).intersection(set(phenotypic_ni_df['ScanDir ID']))\n",
        "print(\"\\nDirect matches between subject_number and ScanDir ID:\", len(common_ids))\n",
        "\n",
        "# Check if the datasets have the same number of rows and might be in the same order\n",
        "print(\"\\nDataset sizes match:\", centrality_ni_df.shape[0] == phenotypic_ni_df.shape[0])\n",
        "\n",
        "# Check for missing values in key columns\n",
        "print(\"\\nMissing values in phenotypic data:\")\n",
        "key_cols = ['DX', 'ADHD Index', 'Inattentive', 'Hyper/Impulsive']\n",
        "for col in key_cols:\n",
        "    if col in phenotypic_ni_df.columns:\n",
        "        missing = phenotypic_ni_df[col].isna().sum()\n",
        "        print(col + \":\", missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22a18c07",
      "metadata": {
        "id": "22a18c07"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Merge on subject identifiers\n",
        "merged_ni_df = pd.merge(centrality_ni_df, phenotypic_ni_df,\n",
        "                        left_on='subject_number', right_on='ScanDir ID', how='inner')\n",
        "\n",
        "print(\"Merged NeuroIMAGE dataset shape:\", merged_ni_df.shape)\n",
        "\n",
        "# Check DX distribution\n",
        "print(\"\\nDX distribution:\")\n",
        "dx_counts = merged_ni_df['DX'].value_counts().sort_index()\n",
        "print(dx_counts)\n",
        "\n",
        "# Since ADHD measures are all missing, let's check what other measures we have\n",
        "print(\"\\nAvailable columns with non-missing data:\")\n",
        "for col in merged_ni_df.columns:\n",
        "    non_missing = merged_ni_df[col].notna().sum()\n",
        "    if non_missing > 0:\n",
        "        print(col + \": \" + str(non_missing) + \" non-missing values\")\n",
        "\n",
        "# Check if there are any ADHD-related measures available\n",
        "adhd_related_cols = [col for col in merged_ni_df.columns if 'adhd' in col.lower() or 'attention' in col.lower() or 'hyperactive' in col.lower()]\n",
        "print(\"\\nADHD-related columns found:\", adhd_related_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb4be5e7",
      "metadata": {
        "id": "eb4be5e7"
      },
      "outputs": [],
      "source": [
        "# Since ADHD symptom measures are missing, we'll focus on group comparisons\n",
        "# Create group labels\n",
        "merged_ni_df['Group'] = merged_ni_df['DX'].apply(lambda x: 'ADHD' if x in [1, 2, 3] else 'TDC')\n",
        "\n",
        "# Define centrality measures (excluding eigenvector which has NaN values)\n",
        "centrality_measures = ['betweenness_centrality', 'closeness_centrality', 'degree_centrality']\n",
        "\n",
        "print(\"NeuroIMAGE Dataset Summary:\")\n",
        "print(\"Total subjects:\", len(merged_ni_df))\n",
        "print(\"TDC (DX=0):\", len(merged_ni_df[merged_ni_df['DX'] == 0]))\n",
        "print(\"ADHD (DX=1,2,3):\", len(merged_ni_df[merged_ni_df['DX'].isin([1, 2, 3])]))\n",
        "\n",
        "# Show detailed DX breakdown\n",
        "print(\"\\nDetailed DX breakdown:\")\n",
        "dx_labels = {0: 'TDC', 1: 'ADHD-Inattentive', 2: 'ADHD-Hyperactive', 3: 'ADHD-Combined'}\n",
        "for dx in sorted(merged_ni_df['DX'].unique()):\n",
        "    count = len(merged_ni_df[merged_ni_df['DX'] == dx])\n",
        "    print(dx_labels.get(dx, 'DX=' + str(int(dx))) + \": \" + str(count) + \" subjects\")\n",
        "\n",
        "# Check centrality data\n",
        "print(\"\\nCentrality measures summary:\")\n",
        "for measure in centrality_measures:\n",
        "    print(measure + \":\")\n",
        "    print(\"  Mean:\", round(merged_ni_df[measure].mean(), 6))\n",
        "    print(\"  Std:\", round(merged_ni_df[measure].std(), 6))\n",
        "    print(\"  Range:\", round(merged_ni_df[measure].min(), 6), \"to\", round(merged_ni_df[measure].max(), 6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c13dfbb",
      "metadata": {
        "id": "0c13dfbb"
      },
      "outputs": [],
      "source": [
        "# Create boxplots comparing ADHD vs TDC groups with p-values\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle('NeuroIMAGE: Centrality Scores by Group (ADHD vs TDC)', fontsize=16)\n",
        "\n",
        "for i, centrality in enumerate(centrality_measures):\n",
        "    ax = axes[i]\n",
        "\n",
        "    # Prepare data for boxplot\n",
        "    adhd_data = merged_ni_df[merged_ni_df['Group'] == 'ADHD'][centrality]\n",
        "    tdc_data = merged_ni_df[merged_ni_df['Group'] == 'TDC'][centrality]\n",
        "\n",
        "    # Create boxplot\n",
        "    bp = ax.boxplot([tdc_data, adhd_data], labels=['TDC', 'ADHD'], patch_artist=True)\n",
        "\n",
        "    # Color the boxes\n",
        "    bp['boxes'][0].set_facecolor('blue')\n",
        "    bp['boxes'][0].set_alpha(0.6)\n",
        "    bp['boxes'][1].set_facecolor('red')\n",
        "    bp['boxes'][1].set_alpha(0.6)\n",
        "\n",
        "    # Perform t-test\n",
        "    t_stat, p_two = stats.ttest_ind(adhd_data, tdc_data)\n",
        "    p_one = p_two / 2  # one-tailed p-value\n",
        "\n",
        "    # Calculate effect size (Cohen's d)\n",
        "    pooled_std = np.sqrt(((len(adhd_data)-1)*adhd_data.var() + (len(tdc_data)-1)*tdc_data.var()) / (len(adhd_data) + len(tdc_data) - 2))\n",
        "    cohens_d = (adhd_data.mean() - tdc_data.mean()) / pooled_std\n",
        "\n",
        "    ax.set_ylabel(centrality.replace('_', ' ').title())\n",
        "    ax.set_title('p = ' + str(round(p_one, 4)) + ' (one-tailed)\\nCohen\\'s d = ' + str(round(cohens_d, 3)))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d99c1d45",
      "metadata": {
        "id": "d99c1d45"
      },
      "outputs": [],
      "source": [
        "# Create detailed boxplots by DX category with p-values\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "fig.suptitle('NeuroIMAGE: Centrality Scores by Detailed DX Categories', fontsize=16)\n",
        "\n",
        "# Define DX categories\n",
        "dx_labels = {0: 'TDC', 1: 'ADHD-Inatt', 2: 'ADHD-Hyper', 3: 'ADHD-Comb'}\n",
        "colors = ['blue', 'orange', 'red', 'purple']\n",
        "\n",
        "for i, centrality in enumerate(centrality_measures):\n",
        "    ax = axes[i]\n",
        "\n",
        "    # Prepare data for each DX category\n",
        "    data_by_dx = []\n",
        "    labels = []\n",
        "    for dx in sorted(merged_ni_df['DX'].unique()):\n",
        "        if len(merged_ni_df[merged_ni_df['DX'] == dx]) > 0:  # Only include if we have data\n",
        "            data_by_dx.append(merged_ni_df[merged_ni_df['DX'] == dx][centrality])\n",
        "            labels.append(dx_labels[dx])\n",
        "\n",
        "    # Create boxplot\n",
        "    bp = ax.boxplot(data_by_dx, labels=labels, patch_artist=True)\n",
        "\n",
        "    # Color the boxes\n",
        "    for j, box in enumerate(bp['boxes']):\n",
        "        box.set_facecolor(colors[j])\n",
        "        box.set_alpha(0.6)\n",
        "\n",
        "    # Perform ANOVA\n",
        "    f_stat, p_anova = stats.f_oneway(*data_by_dx)\n",
        "\n",
        "    ax.set_ylabel(centrality.replace('_', ' ').title())\n",
        "    ax.set_title('ANOVA: F = ' + str(round(f_stat, 3)) + ', p = ' + str(round(p_anova, 4)))\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80586522",
      "metadata": {
        "id": "80586522"
      },
      "outputs": [],
      "source": [
        "# Since ADHD symptom measures are missing in NeuroIMAGE, let's create a comprehensive statistical summary\n",
        "print(\"=== NEUROIMAGE DATASET ANALYSIS ===\")\n",
        "print()\n",
        "\n",
        "# Group comparison statistics\n",
        "print(\"1. GROUP COMPARISONS: ADHD vs TDC\")\n",
        "print(\"----------------------------------------\")\n",
        "\n",
        "for centrality in centrality_measures:\n",
        "    adhd_data = merged_ni_df[merged_ni_df['Group'] == 'ADHD'][centrality]\n",
        "    tdc_data = merged_ni_df[merged_ni_df['Group'] == 'TDC'][centrality]\n",
        "\n",
        "    # T-test\n",
        "    t_stat, p_two = stats.ttest_ind(adhd_data, tdc_data)\n",
        "    p_one = p_two / 2\n",
        "\n",
        "    # Effect size\n",
        "    pooled_std = np.sqrt(((len(adhd_data)-1)*adhd_data.var() + (len(tdc_data)-1)*tdc_data.var()) / (len(adhd_data) + len(tdc_data) - 2))\n",
        "    cohens_d = (adhd_data.mean() - tdc_data.mean()) / pooled_std\n",
        "\n",
        "    print(centrality.replace('_', ' ').title() + \":\")\n",
        "    print(\"  ADHD mean: \" + str(round(adhd_data.mean(), 6)) + \" (n=\" + str(len(adhd_data)) + \")\")\n",
        "    print(\"  TDC mean:  \" + str(round(tdc_data.mean(), 6)) + \" (n=\" + str(len(tdc_data)) + \")\")\n",
        "    print(\"  t = \" + str(round(t_stat, 2)) + \", p = \" + str(round(p_one, 4)) + \" (one-tailed), Cohen's d = \" + str(round(cohens_d, 3)))\n",
        "\n",
        "print()\n",
        "print(\"2. DETAILED DX CATEGORY ANALYSIS\")\n",
        "print(\"-----------------------------------\")\n",
        "\n",
        "dx_labels = {0: 'TDC', 1: 'ADHD-Inattentive', 2: 'ADHD-Hyperactive', 3: 'ADHD-Combined'}\n",
        "\n",
        "for centrality in centrality_measures:\n",
        "    print(centrality.replace('_', ' ').title() + \":\")\n",
        "\n",
        "    # Show means for each group\n",
        "    data_by_dx = []\n",
        "    for dx in sorted(merged_ni_df['DX'].unique()):\n",
        "        subset = merged_ni_df[merged_ni_df['DX'] == dx][centrality]\n",
        "        if len(subset) > 0:\n",
        "            data_by_dx.append(subset)\n",
        "            print(\"  \" + dx_labels[dx] + \": mean = \" + str(round(subset.mean(), 6)) + \" (n=\" + str(len(subset)) + \")\")\n",
        "\n",
        "    # ANOVA\n",
        "    if len(data_by_dx) > 1:\n",
        "        f_stat, p_anova = stats.f_oneway(*data_by_dx)\n",
        "        print(\"  ANOVA: F = \" + str(round(f_stat, 3)) + \", p = \" + str(round(p_anova, 4)))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f04b59bd",
      "metadata": {
        "id": "f04b59bd"
      },
      "outputs": [],
      "source": [
        "# Create a summary table and save results\n",
        "import pandas as pd\n",
        "\n",
        "# Create summary statistics table\n",
        "summary_data = []\n",
        "\n",
        "# ADHD vs TDC comparisons\n",
        "for centrality in centrality_measures:\n",
        "    adhd_data = merged_ni_df[merged_ni_df['Group'] == 'ADHD'][centrality]\n",
        "    tdc_data = merged_ni_df[merged_ni_df['Group'] == 'TDC'][centrality]\n",
        "\n",
        "    t_stat, p_two = stats.ttest_ind(adhd_data, tdc_data)\n",
        "    p_one = p_two / 2\n",
        "\n",
        "    pooled_std = np.sqrt(((len(adhd_data)-1)*adhd_data.var() + (len(tdc_data)-1)*tdc_data.var()) / (len(adhd_data) + len(tdc_data) - 2))\n",
        "    cohens_d = (adhd_data.mean() - tdc_data.mean()) / pooled_std\n",
        "\n",
        "    summary_data.append({\n",
        "        'Measure': centrality.replace('_', ' ').title(),\n",
        "        'ADHD_Mean': round(adhd_data.mean(), 6),\n",
        "        'ADHD_N': len(adhd_data),\n",
        "        'TDC_Mean': round(tdc_data.mean(), 6),\n",
        "        'TDC_N': len(tdc_data),\n",
        "        't_statistic': round(t_stat, 3),\n",
        "        'p_value_one_tailed': round(p_one, 4),\n",
        "        'Cohens_d': round(cohens_d, 3),\n",
        "        'Significance': 'p < 0.05' if p_one < 0.05 else 'n.s.'\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "# Save the results\n",
        "summary_df.to_csv('NeuroIMAGE_centrality_analysis_results.csv', index=False)\n",
        "merged_ni_df.to_csv('NeuroIMAGE_merged_data.csv', index=False)\n",
        "\n",
        "print(\"Analysis complete! Files saved:\")\n",
        "print(\"- NeuroIMAGE_centrality_analysis_results.csv\")\n",
        "print(\"- NeuroIMAGE_merged_data.csv\")\n",
        "print()\n",
        "print(\"Summary of significant findings:\")\n",
        "print(summary_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07792823",
      "metadata": {
        "id": "07792823"
      },
      "source": [
        "\n",
        "## Analysis Summary\n",
        "\n",
        "I've completed the analysis of the NeuroIMAGE dataset comparing centrality scores between ADHD and TDC groups. Here are the key findings:\n",
        "\n",
        "**Important Note**: The NeuroIMAGE dataset does not contain ADHD symptom measures (ADHD Index, Inattentiveness, Hyperactivity/Impulsivity scores are all missing), so I could only perform group comparisons based on diagnostic categories.\n",
        "\n",
        "**Significant Findings**:\n",
        "- **Degree Centrality**: ADHD group showed significantly higher scores than TDC (p = 0.0039, Cohen's d = 0.805)\n",
        "- **Closeness Centrality**: ADHD group showed significantly higher scores than TDC (p = 0.0351, Cohen's d = 0.536)  \n",
        "- **Betweenness Centrality**: Trend toward higher scores in ADHD group (p = 0.0508, Cohen's d = 0.483)\n",
        "\n",
        "The boxplots show clear group differences with p-values included. Since the ADHD symptom measures were unavailable, I couldn't create the requested regression plots between centrality scores and symptom dimensions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a75525ae",
      "metadata": {
        "id": "a75525ae"
      },
      "outputs": [],
      "source": [
        "# Load and examine the OHSU datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# Load the datasets\n",
        "centrality_ohsu = pd.read_csv('centrality_scores_OHSU.csv')\n",
        "phenotypic_ohsu = pd.read_csv('OHSU_phenotypic.csv')\n",
        "\n",
        "print(\"=== OHSU DATASETS OVERVIEW ===\")\n",
        "print(\"Centrality scores shape:\", centrality_ohsu.shape)\n",
        "print(\"Phenotypic data shape:\", phenotypic_ohsu.shape)\n",
        "\n",
        "print(\"\\nCentrality columns:\")\n",
        "for col in centrality_ohsu.columns:\n",
        "    print(\"- \" + col)\n",
        "\n",
        "print(\"\\nPhenotypic columns:\")\n",
        "for col in phenotypic_ohsu.columns:\n",
        "    print(\"- \" + col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d23dbd7b",
      "metadata": {
        "id": "d23dbd7b"
      },
      "outputs": [],
      "source": [
        "# Merge the datasets and examine the data\n",
        "merged_ohsu_df = pd.merge(centrality_ohsu, phenotypic_ohsu, left_on='subject_number', right_on='ScanDir ID', how='inner')\n",
        "\n",
        "print(\"Merged dataset shape:\", merged_ohsu_df.shape)\n",
        "\n",
        "# Replace -999 values with NaN as specified\n",
        "merged_ohsu_df = merged_ohsu_df.replace(-999, np.nan)\n",
        "\n",
        "# Check ADHD measures availability\n",
        "adhd_measures = ['ADHD Index', 'Inattentive', 'Hyper/Impulsive']\n",
        "centrality_measures = ['betweenness_centrality', 'closeness_centrality', 'degree_centrality']\n",
        "\n",
        "print(\"\\nADHD measures data availability:\")\n",
        "for measure in adhd_measures:\n",
        "    non_missing = merged_ohsu_df[measure].notna().sum()\n",
        "    print(measure + \": \" + str(non_missing) + \" non-missing values\")\n",
        "    if non_missing > 0:\n",
        "        print(\"  Range: \" + str(merged_ohsu_df[measure].min()) + \" to \" + str(merged_ohsu_df[measure].max()))\n",
        "\n",
        "print(\"\\nDX distribution:\")\n",
        "print(merged_ohsu_df['DX'].value_counts().sort_index())\n",
        "\n",
        "# Create Group variable (ADHD vs TDC)\n",
        "merged_ohsu_df['Group'] = merged_ohsu_df['DX'].apply(lambda x: 'TDC' if x == 0 else 'ADHD')\n",
        "print(\"\\nGroup distribution:\")\n",
        "print(merged_ohsu_df['Group'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6594ae7e",
      "metadata": {
        "id": "6594ae7e"
      },
      "outputs": [],
      "source": [
        "# Create clean dataset for analysis (removing rows with missing centrality or ADHD measures)\n",
        "# Note: ADHD Index is completely missing, so we'll use Inattentive and Hyper/Impulsive\n",
        "available_adhd_measures = ['Inattentive', 'Hyper/Impulsive']\n",
        "\n",
        "clean_ohsu_df = merged_ohsu_df.dropna(subset=centrality_measures + available_adhd_measures)\n",
        "print(\"Clean dataset size:\", len(clean_ohsu_df), \"subjects\")\n",
        "print(\"Group distribution in clean data:\")\n",
        "print(clean_ohsu_df['Group'].value_counts())\n",
        "\n",
        "# Create scatter plots for centrality scores vs ADHD measures\n",
        "fig, axes = plt.subplots(3, 2, figsize=(12, 15))\n",
        "fig.suptitle('OHSU: Centrality Scores vs ADHD Measures', fontsize=16, y=0.98)\n",
        "\n",
        "for i, centrality in enumerate(centrality_measures):\n",
        "    for j, adhd_measure in enumerate(available_adhd_measures):\n",
        "        ax = axes[i, j]\n",
        "\n",
        "        # Create scatter plot\n",
        "        x = clean_ohsu_df[adhd_measure]\n",
        "        y = clean_ohsu_df[centrality]\n",
        "\n",
        "        # Color by group\n",
        "        colors = ['red' if group == 'ADHD' else 'blue' for group in clean_ohsu_df['Group']]\n",
        "        ax.scatter(x, y, c=colors, alpha=0.6, s=30)\n",
        "\n",
        "        # Calculate correlation and one-tailed p-value\n",
        "        corr, p_value_two_tailed = stats.pearsonr(x, y)\n",
        "        p_value_one_tailed = p_value_two_tailed / 2\n",
        "\n",
        "        # Add correlation and p-value to plot\n",
        "        ax.set_xlabel(adhd_measure)\n",
        "        ax.set_ylabel(centrality.replace('_', ' ').title())\n",
        "        ax.set_title('r = ' + str(round(corr, 3)) + ', p = ' + str(round(p_value_one_tailed, 4)) + ' (one-tailed)')\n",
        "\n",
        "        # Add trend line\n",
        "        z = np.polyfit(x, y, 1)\n",
        "        p = np.poly1d(z)\n",
        "        ax.plot(x, p(x), \"k--\", alpha=0.8, linewidth=1)\n",
        "\n",
        "# Add legend\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [Patch(facecolor='red', label='ADHD'),\n",
        "                   Patch(facecolor='blue', label='TDC')]\n",
        "fig.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(0.98, 0.95))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22d37e85",
      "metadata": {
        "id": "22d37e85"
      },
      "outputs": [],
      "source": [
        "# Create box plots comparing ADHD vs TDC groups for centrality measures\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle('OHSU: Centrality Scores by Group (ADHD vs TDC)', fontsize=16)\n",
        "\n",
        "for i, centrality in enumerate(centrality_measures):\n",
        "    ax = axes[i]\n",
        "\n",
        "    # Create box plot\n",
        "    groups = ['TDC', 'ADHD']\n",
        "    data_to_plot = [clean_ohsu_df[clean_ohsu_df['Group'] == group][centrality] for group in groups]\n",
        "\n",
        "    box_plot = ax.boxplot(data_to_plot, labels=groups, patch_artist=True)\n",
        "    box_plot['boxes'][0].set_facecolor('blue')\n",
        "    box_plot['boxes'][1].set_facecolor('red')\n",
        "\n",
        "    # Perform t-test (one-tailed)\n",
        "    tdc_data = clean_ohsu_df[clean_ohsu_df['Group'] == 'TDC'][centrality]\n",
        "    adhd_data = clean_ohsu_df[clean_ohsu_df['Group'] == 'ADHD'][centrality]\n",
        "\n",
        "    t_stat, p_value_two_tailed = stats.ttest_ind(adhd_data, tdc_data)\n",
        "    p_value_one_tailed = p_value_two_tailed / 2\n",
        "\n",
        "    # Calculate Cohen's d\n",
        "    pooled_std = np.sqrt(((len(adhd_data) - 1) * adhd_data.var() + (len(tdc_data) - 1) * tdc_data.var()) / (len(adhd_data) + len(tdc_data) - 2))\n",
        "    cohens_d = (adhd_data.mean() - tdc_data.mean()) / pooled_std\n",
        "\n",
        "    ax.set_ylabel(centrality.replace('_', ' ').title())\n",
        "    ax.set_title('p = ' + str(round(p_value_one_tailed, 4)) + ' (one-tailed)\\nd = ' + str(round(cohens_d, 3)))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print statistical summary\n",
        "print(\"\\n=== STATISTICAL SUMMARY ===\")\n",
        "print(\"Group Comparisons (ADHD vs TDC):\")\n",
        "for centrality in centrality_measures:\n",
        "    tdc_data = clean_ohsu_df[clean_ohsu_df['Group'] == 'TDC'][centrality]\n",
        "    adhd_data = clean_ohsu_df[clean_ohsu_df['Group'] == 'ADHD'][centrality]\n",
        "\n",
        "    t_stat, p_value_two_tailed = stats.ttest_ind(adhd_data, tdc_data)\n",
        "    p_value_one_tailed = p_value_two_tailed / 2\n",
        "\n",
        "    pooled_std = np.sqrt(((len(adhd_data) - 1) * adhd_data.var() + (len(tdc_data) - 1) * tdc_data.var()) / (len(adhd_data) + len(tdc_data) - 2))\n",
        "    cohens_d = (adhd_data.mean() - tdc_data.mean()) / pooled_std\n",
        "\n",
        "    significance = \"***\" if p_value_one_tailed < 0.001 else \"**\" if p_value_one_tailed < 0.01 else \"*\" if p_value_one_tailed < 0.05 else \"n.s.\"\n",
        "\n",
        "    print(centrality + \":\")\n",
        "    print(\"  ADHD: M = \" + str(round(adhd_data.mean(), 6)) + \", N = \" + str(len(adhd_data)))\n",
        "    print(\"  TDC:  M = \" + str(round(tdc_data.mean(), 6)) + \", N = \" + str(len(tdc_data)))\n",
        "    print(\"  t = \" + str(round(t_stat, 3)) + \", p = \" + str(round(p_value_one_tailed, 4)) + \" (one-tailed), d = \" + str(round(cohens_d, 3)) + \" \" + significance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3c42804",
      "metadata": {
        "id": "d3c42804"
      },
      "outputs": [],
      "source": [
        "# Create box plots comparing specific ADHD subtypes (DX = 1,2,3) vs TDC (DX = 0)\n",
        "print(\"DX category breakdown:\")\n",
        "dx_counts = clean_ohsu_df['DX'].value_counts().sort_index()\n",
        "print(dx_counts)\n",
        "\n",
        "# Create detailed group labels\n",
        "clean_ohsu_df['DX_Group'] = clean_ohsu_df['DX'].map({\n",
        "    0: 'TDC',\n",
        "    1: 'ADHD-Inattentive',\n",
        "    2: 'ADHD-Hyperactive',\n",
        "    3: 'ADHD-Combined'\n",
        "})\n",
        "\n",
        "print(\"\\nDetailed group distribution:\")\n",
        "print(clean_ohsu_df['DX_Group'].value_counts())\n",
        "\n",
        "# Create box plots for detailed ADHD subtypes\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "fig.suptitle('OHSU: Centrality Scores by ADHD Subtype', fontsize=16)\n",
        "\n",
        "for i, centrality in enumerate(centrality_measures):\n",
        "    ax = axes[i]\n",
        "\n",
        "    # Create box plot with all groups\n",
        "    groups = ['TDC', 'ADHD-Inattentive', 'ADHD-Hyperactive', 'ADHD-Combined']\n",
        "    data_to_plot = []\n",
        "    colors = ['blue', 'red', 'orange', 'purple']\n",
        "\n",
        "    for group in groups:\n",
        "        group_data = clean_ohsu_df[clean_ohsu_df['DX_Group'] == group][centrality]\n",
        "        if len(group_data) > 0:\n",
        "            data_to_plot.append(group_data)\n",
        "        else:\n",
        "            data_to_plot.append([])\n",
        "\n",
        "    box_plot = ax.boxplot(data_to_plot, labels=groups, patch_artist=True)\n",
        "\n",
        "    # Color the boxes\n",
        "    for patch, color in zip(box_plot['boxes'], colors):\n",
        "        patch.set_facecolor(color)\n",
        "\n",
        "    # Perform ANOVA\n",
        "    group_data_list = [clean_ohsu_df[clean_ohsu_df['DX_Group'] == group][centrality].values\n",
        "                       for group in groups if len(clean_ohsu_df[clean_ohsu_df['DX_Group'] == group]) > 0]\n",
        "\n",
        "    if len(group_data_list) > 1:\n",
        "        f_stat, p_value = stats.f_oneway(*group_data_list)\n",
        "        ax.set_title('ANOVA: F = ' + str(round(f_stat, 3)) + ', p = ' + str(round(p_value, 4)))\n",
        "\n",
        "    ax.set_ylabel(centrality.replace('_', ' ').title())\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Perform detailed statistical comparisons\n",
        "print(\"\\n=== DETAILED SUBTYPE ANALYSIS ===\")\n",
        "for centrality in centrality_measures:\n",
        "    print(\"\\n\" + centrality.upper() + \":\")\n",
        "\n",
        "    # Get data for each group\n",
        "    tdc_data = clean_ohsu_df[clean_ohsu_df['DX'] == 0][centrality]\n",
        "    inatt_data = clean_ohsu_df[clean_ohsu_df['DX'] == 1][centrality]\n",
        "    hyper_data = clean_ohsu_df[clean_ohsu_df['DX'] == 2][centrality]\n",
        "    combined_data = clean_ohsu_df[clean_ohsu_df['DX'] == 3][centrality]\n",
        "\n",
        "    # Print descriptives\n",
        "    print(\"  TDC (n=\" + str(len(tdc_data)) + \"): M = \" + str(round(tdc_data.mean(), 6)))\n",
        "    print(\"  ADHD-Inattentive (n=\" + str(len(inatt_data)) + \"): M = \" + str(round(inatt_data.mean(), 6)))\n",
        "    print(\"  ADHD-Hyperactive (n=\" + str(len(hyper_data)) + \"): M = \" + str(round(hyper_data.mean(), 6)))\n",
        "    print(\"  ADHD-Combined (n=\" + str(len(combined_data)) + \"): M = \" + str(round(combined_data.mean(), 6)))\n",
        "\n",
        "    # ANOVA\n",
        "    f_stat, p_value = stats.f_oneway(tdc_data, inatt_data, hyper_data, combined_data)\n",
        "    print(\"  ANOVA: F = \" + str(round(f_stat, 3)) + \", p = \" + str(round(p_value, 4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef6a4a58",
      "metadata": {
        "id": "ef6a4a58"
      },
      "outputs": [],
      "source": [
        "# Save the analysis results\n",
        "results_summary = {\n",
        "    'Dataset': 'OHSU',\n",
        "    'Total_Subjects': len(clean_ohsu_df),\n",
        "    'TDC_Count': len(clean_ohsu_df[clean_ohsu_df['Group'] == 'TDC']),\n",
        "    'ADHD_Count': len(clean_ohsu_df[clean_ohsu_df['Group'] == 'ADHD']),\n",
        "    'ADHD_Inattentive_Count': len(clean_ohsu_df[clean_ohsu_df['DX'] == 1]),\n",
        "    'ADHD_Hyperactive_Count': len(clean_ohsu_df[clean_ohsu_df['DX'] == 2]),\n",
        "    'ADHD_Combined_Count': len(clean_ohsu_df[clean_ohsu_df['DX'] == 3])\n",
        "}\n",
        "\n",
        "# Create correlation summary\n",
        "correlation_results = []\n",
        "for centrality in centrality_measures:\n",
        "    for adhd_measure in available_adhd_measures:\n",
        "        x = clean_ohsu_df[adhd_measure]\n",
        "        y = clean_ohsu_df[centrality]\n",
        "        corr, p_value_two_tailed = stats.pearsonr(x, y)\n",
        "        p_value_one_tailed = p_value_two_tailed / 2\n",
        "\n",
        "        correlation_results.append({\n",
        "            'Centrality_Measure': centrality,\n",
        "            'ADHD_Measure': adhd_measure,\n",
        "            'Correlation': corr,\n",
        "            'P_Value_One_Tailed': p_value_one_tailed,\n",
        "            'N': len(x)\n",
        "        })\n",
        "\n",
        "correlation_df = pd.DataFrame(correlation_results)\n",
        "\n",
        "# Create group comparison summary\n",
        "group_comparison_results = []\n",
        "for centrality in centrality_measures:\n",
        "    tdc_data = clean_ohsu_df[clean_ohsu_df['Group'] == 'TDC'][centrality]\n",
        "    adhd_data = clean_ohsu_df[clean_ohsu_df['Group'] == 'ADHD'][centrality]\n",
        "\n",
        "    t_stat, p_value_two_tailed = stats.ttest_ind(adhd_data, tdc_data)\n",
        "    p_value_one_tailed = p_value_two_tailed / 2\n",
        "\n",
        "    pooled_std = np.sqrt(((len(adhd_data) - 1) * adhd_data.var() + (len(tdc_data) - 1) * tdc_data.var()) / (len(adhd_data) + len(tdc_data) - 2))\n",
        "    cohens_d = (adhd_data.mean() - tdc_data.mean()) / pooled_std\n",
        "\n",
        "    group_comparison_results.append({\n",
        "        'Centrality_Measure': centrality,\n",
        "        'ADHD_Mean': adhd_data.mean(),\n",
        "        'TDC_Mean': tdc_data.mean(),\n",
        "        'T_Statistic': t_stat,\n",
        "        'P_Value_One_Tailed': p_value_one_tailed,\n",
        "        'Cohens_D': cohens_d,\n",
        "        'ADHD_N': len(adhd_data),\n",
        "        'TDC_N': len(tdc_data)\n",
        "    })\n",
        "\n",
        "group_comparison_df = pd.DataFrame(group_comparison_results)\n",
        "\n",
        "# Save results\n",
        "correlation_df.to_csv('OHSU_correlation_analysis_results.csv', index=False)\n",
        "group_comparison_df.to_csv('OHSU_group_comparison_results.csv', index=False)\n",
        "clean_ohsu_df.to_csv('OHSU_merged_data.csv', index=False)\n",
        "\n",
        "print(\"Analysis complete! Files saved:\")\n",
        "print(\"- OHSU_correlation_analysis_results.csv\")\n",
        "print(\"- OHSU_group_comparison_results.csv\")\n",
        "print(\"- OHSU_merged_data.csv\")\n",
        "\n",
        "print(\"\\nCorrelation Results Summary:\")\n",
        "print(correlation_df.round(4))\n",
        "\n",
        "print(\"\\nGroup Comparison Results Summary:\")\n",
        "print(group_comparison_df.round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32dc2d7a",
      "metadata": {
        "id": "32dc2d7a"
      },
      "source": [
        "\n",
        "## OHSU Dataset Analysis Results\n",
        "\n",
        "\n",
        "\n",
        "### Dataset Overview\n",
        "\n",
        "\n",
        "**Important Note**: The ADHD Index column was completely missing (all NaN values), so the analysis focused on **Inattentive** and **Hyper/Impulsive** measures, which had complete data for all subjects.\n",
        "\n",
        "\n",
        "\n",
        "### Correlation Analysis (Scatter Plots)\n",
        "The scatter plots show relationships between centrality measures and ADHD symptom scores, with correlation coefficients and one-tailed p-values:\n",
        "\n",
        "\n",
        "**Key Findings**:\n",
        "- **Closeness centrality** showed the strongest correlations with both Inattentive (r = 0.18, p = 0.063) and Hyper/Impulsive (r = 0.17, p = 0.077) measures\n",
        "- All correlations were positive but modest in magnitude\n",
        "- None reached statistical significance at p < 0.05 level\n",
        "\n",
        "### Group Comparisons (ADHD vs TDC)\n",
        "\n",
        "\n",
        "**Key Findings**:\n",
        "- ADHD group consistently showed **higher centrality scores** than TDC across all measures\n",
        "- **Betweenness centrality** showed the largest effect size (Cohen's d = 0.38) and approached significance (p = 0.058)\n",
        "- Effect sizes were small to medium but none reached statistical significance\n",
        "\n",
        "### ADHD Subtype Analysis\n",
        "\n",
        "\n",
        "**ANOVA results** showed no significant differences between ADHD subtypes and TDC (all p > 0.05).\n",
        "\n",
        "### Summary\n",
        "The OHSU dataset shows **consistent trends** where individuals with ADHD have higher brain network centrality scores compared to typically developing controls, particularly for betweenness centrality. However, these differences did not reach statistical significance, possibly due to the relatively small sample size (n=72) and modest effect sizes.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}